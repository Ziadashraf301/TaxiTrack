services:
  postgres_airflow:
    image: postgres:16
    container_name: postgres_airflow
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - ./postgres_airflow:/var/lib/postgresql/data

  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    mem_limit: 2g
    ports:
      - "${MINIO_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":${MINIO_CONSOLE_PORT}"
    volumes:
      - ./minio_storage:/data

  clickhouse:
    image: clickhouse/clickhouse-server:24.3.8
    container_name: clickhouse
    hostname: clickhouse
    ports:
      - "${CLICKHOUSE_HTTP_PORT}:8123"
      - "${CLICKHOUSE_TCP_PORT}:9000"
    environment:
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_DB: ${CLICKHOUSE_DB}
    volumes:
      - clickhouse_data_warehouse:/var/lib/clickhouse

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    ports:
      - "3000:3000"
    environment:
      MB_DB_TYPE: ${MB_DB_TYPE}
      MB_DB_DBNAME: ${MB_DB_DBNAME}
      MB_DB_PORT: ${MB_DB_PORT}
      MB_DB_USER: ${MB_DB_USER}
      MB_DB_PASS: ${MB_DB_PASS}
      MB_DB_HOST: ${MB_DB_HOST}
    volumes:
      - metabase_data:/metabase-data

  airflow-init:
    build:       
      context: .
      dockerfile: airflow/docker/Dockerfile
    depends_on:
      - postgres_airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DEFAULT_TIMEZONE: ${AIRFLOW_DEFAULT_TIMEZONE}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
      AIRFLOW__SMTP__SMTP_HOST: ${SMTP_HOST}
      AIRFLOW__SMTP__SMTP_PORT: ${SMTP_PORT}
      AIRFLOW__SMTP__SMTP_STARTTLS: ${SMTP_STARTTLS}
      AIRFLOW__SMTP__SMTP_SSL: ${SMTP_SSL}
      AIRFLOW__SMTP__SMTP_USER: ${SMTP_USER}
      AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD}
      AIRFLOW__SMTP__SMTP_MAIL_FROM: ${SMTP_MAIL_FROM}
    entrypoint: >
      bash -c "
        airflow db migrate &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email ziadashraf98765@gmail.com
      "

    volumes: 
      - ./airflow/dags:/opt/airflow/dags 
      - ./airflow/src/ingestion:/opt/airflow/src/ingestion 
      - ./airflow/airflow_logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock

  # Airflow Webserver
  airflow-webserver:
    build:       
      context: .
      dockerfile: airflow/docker/Dockerfile
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres_airflow
      - airflow-init
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DEFAULT_TIMEZONE: ${AIRFLOW_DEFAULT_TIMEZONE}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
      AIRFLOW__WEBSERVER__SESSION_BACKEND: securecookie
      AIRFLOW__SMTP__SMTP_HOST: ${SMTP_HOST}
      AIRFLOW__SMTP__SMTP_PORT: ${SMTP_PORT}
      AIRFLOW__SMTP__SMTP_STARTTLS: ${SMTP_STARTTLS}
      AIRFLOW__SMTP__SMTP_SSL: ${SMTP_SSL}
      AIRFLOW__SMTP__SMTP_USER: ${SMTP_USER}
      AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD}
      AIRFLOW__SMTP__SMTP_MAIL_FROM: ${SMTP_MAIL_FROM}
      PYTHONPATH: /opt/airflow/src:/opt/airflow/src
    command: webserver
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/src/ingestion:/opt/airflow/src/ingestion
      - ./airflow/airflow_logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock

  # Airflow Scheduler
  airflow-scheduler:
    build: 
      context: .
      dockerfile: airflow/docker/Dockerfile
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_SQL_ALCHEMY_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DEFAULT_TIMEZONE: ${AIRFLOW_DEFAULT_TIMEZONE}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
      AIRFLOW__SMTP__SMTP_HOST: ${SMTP_HOST}
      AIRFLOW__SMTP__SMTP_PORT: ${SMTP_PORT}
      AIRFLOW__SMTP__SMTP_STARTTLS: ${SMTP_STARTTLS}
      AIRFLOW__SMTP__SMTP_SSL: ${SMTP_SSL}
      AIRFLOW__SMTP__SMTP_USER: ${SMTP_USER}
      AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD}
      AIRFLOW__SMTP__SMTP_MAIL_FROM: ${SMTP_MAIL_FROM}
      PYTHONPATH: /opt/airflow/src:/opt/airflow/src
    command: scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/src/ingestion:/opt/airflow/src/ingestion
      - ./airflow/airflow_logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock



  # dbt (Data Build Tool
  dbt:
    build:
      context: .
      dockerfile: dbt/docker/Dockerfile
    container_name: dbt
    volumes:
      - ./dbt:/dbt
      - ./dbt/profiles.yml:/root/.dbt/profiles.yml
    working_dir: /dbt
    entrypoint: /bin/bash  # Override the default entrypoint
    command: -c "tail -f /dev/null"  # Keep the container running



# Named Volumes
volumes:
  postgres_airflow:
  metabase_data:
  clickhouse_data_warehouse:
  minio_storage:
